# ğŸ§  AI Data Analyst â€“ Proof of Concept

This is a proof-of-concept (PoC) for an AI-powered data analyst. It allows business users to:

- âœ… Upload Excel datasets
- âœ… Ask natural language questions
- âœ… Automatically generate SQL queries
- âœ… Run those queries on structured data
- âœ… Receive AI-generated summaries and insights

---

## ğŸš€ Features

- ğŸ¤– Uses GPT-4o(-mini) to translate questions into SQL
- ğŸ“Š Executes SQL queries on a local SQLite database
- ğŸ’¡ AI interprets query results to provide insights
- ğŸ–¥ï¸ Simple UI built with Streamlit
- ğŸ³ Dockerized for easy deployment

---

## ğŸ—‚ï¸ Project Structure

ai-data-analyst-poc\ <br>
| <br>
|_app\ <br>
|____db\ <br>
|______db.py <br>
|______my_db.db <br>
|____services\ <br>
|______llm_service.py <br>
|______query_executor.py <br>
|____app.py <br/>
|_dockerignore <br>
|_Dockerfile <br>
|_env <br>
|_requirements.txt <br>
|_README.md


---

## âš™ï¸ Installation & Usage

### â–¶ï¸ Run Locally

1. Clone the repo:
    ```bash
    git clone repo
    cd ai-data-analyst-poc
    ```

2. Set up virtual environment:
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3. Install dependencies:
    ```bash
    pip install -r requirements.txt
    ```

4. Set environment variables in `.env`:
    ```env
    API_KEY=your-openai-api-key
    PATH_TO_DB=/absolute/or/relative/path/to/db/my_db.db
    PATH_TO_DATA=/absolute/or/relative/path/to/data/Data_Pump.xlsx
    ```

5. Run the app:
    ```bash
    streamlit run app.py
    ```

---

### ğŸ³ Run with Docker

1. Build Docker image:
    ```bash
    docker build -t ai-data-analyst .
    ```

2. Run container:
    ```bash
    docker run -p 8501:8501 ai-data-analyst
    ```

3. Open [http://localhost:8501](http://localhost:8501)

---

## ğŸ“¥ Uploading Data

- Upload `.xlsx` files using the UI.
- The app converts them into a temporary SQLite database.
- You can then ask natural questions like:
  > "Which months had the highest revenue?"  
  > "What is the highest/lowest transaction value for each Posting period?"

---

## ğŸ§  Technologies Used

- **OpenAI GPT-4o(-mini)** â€“ Natural language to SQL + Insight generation
- **Streamlit** â€“ UI
- **SQLite** â€“ Lightweight local database
- **Python** â€“ Main language
- **Docker** â€“ Deployment & containerization
- **FastAPI (optional)** â€“ For backend services (can be added later)
---

## ğŸ“Œ TODO / Ideas for Improvement

- Add support for chart suggestions & visualizations
- Improve error handling / SQL retry logic
- Add advanced full-scale backend with FastAPI
- Add user authentication (if used in production)
- Expand LLM prompt training with few-shot examples
